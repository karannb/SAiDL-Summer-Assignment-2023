{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26111f0c",
   "metadata": {},
   "source": [
    "# SAiDL Summer 2023, Computer Vision - Bonus Part"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28454ff5",
   "metadata": {},
   "source": [
    "## Investigating the claim \"Pixel intensities in a grayscale image vary smoothly within an object, as opposed intensities from pixels that cross object boundaries or belong to different objects.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6073e2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import clip\n",
    "from PIL import Image\n",
    "from IPython.display import Image as Displayer\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b55cdff",
   "metadata": {},
   "source": [
    "## Welch's T-test -"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ac7fe3",
   "metadata": {},
   "source": [
    "### t-value calculation -"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eccb7bc",
   "metadata": {},
   "source": [
    "![t-value calculation](t-value.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf01902",
   "metadata": {},
   "source": [
    "### DOF calculation -"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e185234a",
   "metadata": {},
   "source": [
    "![](degrees_of_freedom.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af43fdb3",
   "metadata": {},
   "source": [
    "### Validation set -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c803bad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6828\n",
      "6828\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(10)\n",
    "\n",
    "data_same_object = []\n",
    "data_diff_object = []\n",
    "\n",
    "val_data = PhraseCutDataset_('val')\n",
    "val = DataLoader(val_data, batch_size=1)\n",
    "\n",
    "for (phrase, input_img, output_map, task_id) in val:\n",
    "    \n",
    "    if(len(input_img.shape) != 4):\n",
    "        continue\n",
    "    \n",
    "    temp = input_img.numpy().astype(np.uint8)\n",
    "    grayscale_img = Image.fromarray(temp[0], 'RGB').convert('L')\n",
    "    grayscale_array = np.array(grayscale_img)\n",
    "    \n",
    "    #print(output_map.shape)\n",
    "    \n",
    "    x = np.random.randint(0, 224)\n",
    "    y = np.random.randint(0, 224)\n",
    "    \n",
    "    my_pixel = grayscale_array[x][y]\n",
    "    my_label = output_map[0][x][y]\n",
    "    \n",
    "    grayscale_array = np.abs(grayscale_array - my_pixel)\n",
    "    \n",
    "    data_same_object.append(np.mean(grayscale_array[output_map[0]==my_label]))\n",
    "    data_diff_object.append(np.mean(grayscale_array[output_map[0]!=my_label]))\n",
    "    \n",
    "    #print(x, y)\n",
    "    #print(grayscale_array)\n",
    "    #print(my_pixel)\n",
    "    #break\n",
    "    \n",
    "print(len(data_diff_object))\n",
    "print(len(data_same_object))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "305084d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.8031026151546823\n",
      "12843.217203106984\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "n1 = len(data_diff_object)\n",
    "n2 = len(data_same_object)\n",
    "\n",
    "arr1 = np.array(data_diff_object)\n",
    "arr2 = np.array(data_same_object)\n",
    "\n",
    "mu1 = np.mean(arr1)\n",
    "mu2 = np.mean(arr2)\n",
    "\n",
    "s1 = np.std(arr1)\n",
    "s2 = np.std(arr2)\n",
    "\n",
    "std_err1 = (s1**2)/n1\n",
    "std_err2 = (s2**2)/n2\n",
    "\n",
    "#print(s1, s2, std_err1, std_err2)\n",
    "\n",
    "#print(std_err1)\n",
    "#print(std_err2)\n",
    "\n",
    "t = np.abs(mu1-mu2)/math.sqrt(std_err1 + std_err2)\n",
    "\n",
    "v = ((std_err1 + std_err2)**2)/((std_err1**2)/(n1-1) + (std_err2**2)/(n2-1))\n",
    "\n",
    "print(t)\n",
    "print(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4239829e",
   "metadata": {},
   "source": [
    "![t-table values](t-table-val.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "360f964e",
   "metadata": {},
   "source": [
    "### Clearly the two populations have <u>different means</u> and a statistically significant difference, because even at 99.9% confidence interval and âˆž degrees of freedom the t-value is still an outlier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5024b4e",
   "metadata": {},
   "source": [
    "### Train set -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6c75dd36",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = PhraseCutDataset_('train')\n",
    "train = DataLoader(train_data, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8fb61f6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30732\n",
      "30732\n"
     ]
    }
   ],
   "source": [
    "data_same_object = []\n",
    "data_diff_object = []\n",
    "\n",
    "for (phrase, input_img, output_map, task_id) in train:\n",
    "    \n",
    "    if(len(input_img.shape) != 4):\n",
    "        continue\n",
    "    \n",
    "    temp = input_img.numpy().astype(np.uint8)\n",
    "    grayscale_img = Image.fromarray(temp[0], 'RGB').convert('L')\n",
    "    grayscale_array = np.array(grayscale_img)\n",
    "    \n",
    "    #print(output_map.shape)\n",
    "    \n",
    "    x = np.random.randint(0, 224)\n",
    "    y = np.random.randint(0, 224)\n",
    "    \n",
    "    my_pixel = grayscale_array[x][y]\n",
    "    my_label = output_map[0][x][y]\n",
    "    \n",
    "    grayscale_array = np.abs(grayscale_array - my_pixel)\n",
    "    \n",
    "    if(False in (output_map[0]!=my_label)):\n",
    "        data_same_object.append(np.mean(grayscale_array[output_map[0]==my_label]))\n",
    "    else:\n",
    "        data_same_object.append(0)\n",
    "    \n",
    "    if(False in (output_map[0]==my_label)):\n",
    "        data_diff_object.append(np.mean(grayscale_array[output_map[0]!=my_label]))\n",
    "    else:\n",
    "        data_diff_object.append(0)\n",
    "    \n",
    "    #print(x, y)\n",
    "    #print(grayscale_array)\n",
    "    #print(my_pixel)\n",
    "    #break\n",
    "    \n",
    "print(len(data_diff_object))\n",
    "print(len(data_same_object))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8f72c594",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t-value - 6.235643450265331\n",
      "degrees of freedom - 59410.94251361604\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "n1 = len(data_diff_object)\n",
    "n2 = len(data_same_object)\n",
    "\n",
    "arr1 = np.array(data_diff_object)\n",
    "arr2 = np.array(data_same_object)\n",
    "\n",
    "mu1 = np.mean(arr1)\n",
    "mu2 = np.mean(arr2)\n",
    "\n",
    "s1 = np.std(arr1)\n",
    "s2 = np.std(arr2)\n",
    "\n",
    "std_err1 = (s1**2)/n1\n",
    "std_err2 = (s2**2)/n2\n",
    "\n",
    "#print(s1, s2, std_err1, std_err2)\n",
    "\n",
    "#print(std_err1)\n",
    "#print(std_err2)\n",
    "\n",
    "t = np.abs(mu1-mu2)/math.sqrt(std_err1 + std_err2)\n",
    "\n",
    "v = ((std_err1 + std_err2)**2)/((std_err1**2)/(n1-1) + (std_err2**2)/(n2-1))\n",
    "\n",
    "print(f\"t-value - {t}\")\n",
    "print(f\"degrees of freedom - {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f85685fd",
   "metadata": {},
   "source": [
    "![t-table values](t-table-train.tiff)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98691493",
   "metadata": {},
   "source": [
    "### The hypothesis is strengthened by the train set result."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CLIPSeg",
   "language": "python",
   "name": "clipseg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
